{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SportsMonks Predictive Analysis\n",
    "\n",
    "Using the data gathered through the [Sports Monks API](https://www.sportmonks.com/), we can begin to analyze the match and player data and try to predict match outcomes. We can do this with the [SciKit-Learn library](http://scikit-learn.org/stable/), which provides a collection of machine learning models that can be tuned to the specific problem.\n",
    "\n",
    "Specifically, we're going to be using the [Supervised Neural Networks Classifier](http://scikit-learn.org/stable/modules/neural_networks_supervised.html) in the SciKit-Learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, we need to set up access to the local SportsMonks database, as well as importing [Pandas](http://pandas.pydata.org/pandas-docs/version/0.23/) and [Numpy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sys.path.insert(0, './internal')\n",
    "import databaseinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://{}:{}@{}/{}'.format(\n",
    "    databaseinfo.db_user(),\n",
    "    databaseinfo.db_passwd(),\n",
    "    databaseinfo.db_host(),\n",
    "    databaseinfo.db_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to retrieve and merge the Club Season data and the Starting Lineup data for each match, for both the home and away teams. For ease of access, the starting lineup statistics for each team have been precomputed and inserted into a table, LineupStats. After this is done, we can use this data to train the Neural Network and determine the optimal number of hidden layers and nodes that gives us the most accurate match prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSqlRename(tableName, attribute, prefix):\n",
    "    return \"%s.%s as %s%s\" % (tableName, attribute, prefix, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_attributes = [\n",
    "    \"minutes_played\",\n",
    "    \"appearances\",\n",
    "    \"goals\",\n",
    "    \"goals_conceded\",\n",
    "    \"assists\",\n",
    "    \"shots_on_goal\",\n",
    "    \"shots_total\",\n",
    "    \"fouls_committed\",\n",
    "    \"fouls_drawn\",\n",
    "    \"interceptions\",\n",
    "    \"saves\",\n",
    "    \"clearances\",\n",
    "    \"tackles\",\n",
    "    \"offsides\",\n",
    "    \"blocks\",\n",
    "    \"pen_saved\",\n",
    "    \"pen_missed\",\n",
    "    \"pen_scored\",\n",
    "    \"passes_total\",\n",
    "    \"crosses_total\"\n",
    "]\n",
    "\n",
    "def player_rename(tableName, attribute, prefix):\n",
    "    return \"%s.%s as %s%s\" % (tableName, attribute, prefix, attribute)\n",
    "\n",
    "def home_player_rename(attribute):\n",
    "    return player_rename(\"ls\", attribute, \"home_\")\n",
    "\n",
    "def away_player_rename(attribute):\n",
    "    return player_rename(\"ls\", attribute, \"away_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homeRename(attribute):\n",
    "    return toSqlRename(\"css\", attribute, \"home_\")\n",
    "\n",
    "def awayRename(attribute):\n",
    "    return toSqlRename(\"css\", attribute, \"away_\")\n",
    "\n",
    "attributes = [\n",
    "    \"win_total\",\n",
    "    \"draw_total\",\n",
    "    \"lost_total\",\n",
    "    \"goals_for_total\",\n",
    "    \"goals_against_total\",\n",
    "    \"clean_sheet_total\",\n",
    "    \"failed_to_score_total\"\n",
    "]\n",
    "\n",
    "home_string = \", \".join(list(map(homeRename, attributes)))\n",
    "home_players_string = \", \".join(list(map(home_player_rename, player_attributes)))\n",
    "away_string = \", \".join(list(map(awayRename, attributes)))\n",
    "away_players_string = \", \".join(list(map(away_player_rename, player_attributes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_attribute_query = \"SELECT home.*, %s, %s \\\n",
    "FROM (  SELECT f.*, %s, %s \\\n",
    "        FROM Fixture f, ClubSeasonStats css, LineupStats ls \\\n",
    "        WHERE f.season_id=css.season_id \\\n",
    "            AND f.home_team_id=css.club_id \\\n",
    "            AND f.id=ls.fixture_id \\\n",
    "            AND f.home_team_id=ls.club_id \\\n",
    "     ) home, \\\n",
    "    ClubSeasonStats css, \\\n",
    "    LineupStats ls \\\n",
    "WHERE home.season_id=css.season_id \\\n",
    "    AND home.away_team_id=css.club_id  \\\n",
    "    AND home.id=ls.fixture_id \\\n",
    "    AND home.away_team_id=ls.club_id\" % (away_string, away_players_string, home_string, home_players_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resoverall = engine.execute(club_attribute_query)\n",
    "df = pd.DataFrame(resoverall.fetchall())\n",
    "df.columns = resoverall.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Match Outcome\n",
    "Now that we have the data, we need to do something with it. Initially, let's just look at the overall result of a game, giving the three outcomes a corresponding label:\n",
    "* Home team wins: '0'\n",
    "* Teams draw: '1'\n",
    "* Away team wins: '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(scores):\n",
    "    home_score = scores[0]\n",
    "    away_score = scores[1]\n",
    "    \n",
    "    if home_score > away_score:\n",
    "        return '0'\n",
    "    elif home_score == away_score:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.loc[:, ['home_team_score', 'away_team_score']]\n",
    "df['Result'] = scores.apply(getResult, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>date_of_game</th>\n",
       "      <th>home_team_score</th>\n",
       "      <th>away_team_score</th>\n",
       "      <th>home_win_total</th>\n",
       "      <th>home_draw_total</th>\n",
       "      <th>...</th>\n",
       "      <th>away_clearances</th>\n",
       "      <th>away_tackles</th>\n",
       "      <th>away_offsides</th>\n",
       "      <th>away_blocks</th>\n",
       "      <th>away_pen_saved</th>\n",
       "      <th>away_pen_missed</th>\n",
       "      <th>away_pen_scored</th>\n",
       "      <th>away_passes_total</th>\n",
       "      <th>away_crosses_total</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2188</td>\n",
       "      <td>13</td>\n",
       "      <td>199</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>358</td>\n",
       "      <td>38</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8057</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2197</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>333</td>\n",
       "      <td>28</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8942</td>\n",
       "      <td>277</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2208</td>\n",
       "      <td>13</td>\n",
       "      <td>201</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>312</td>\n",
       "      <td>34</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7248</td>\n",
       "      <td>288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2216</td>\n",
       "      <td>13</td>\n",
       "      <td>202</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>461</td>\n",
       "      <td>37</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14887</td>\n",
       "      <td>526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2225</td>\n",
       "      <td>13</td>\n",
       "      <td>203</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>310</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6376</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  season_id  venue_id  home_team_id  away_team_id date_of_game  \\\n",
       "0  2188         13       199            22            42   2016-08-13   \n",
       "1  2197         13       200            27            30   2016-08-13   \n",
       "2  2208         13       201            51            10   2016-08-13   \n",
       "3  2216         13       202            13             6   2016-08-13   \n",
       "4  2225         13       203             7            26   2016-08-13   \n",
       "\n",
       "   home_team_score  away_team_score  home_win_total  home_draw_total   ...    \\\n",
       "0                2                1               9                7   ...     \n",
       "1                0                1              11                7   ...     \n",
       "2                0                1              12                5   ...     \n",
       "3                1                1              17               10   ...     \n",
       "4                1                1               5               13   ...     \n",
       "\n",
       "   away_clearances  away_tackles  away_offsides  away_blocks  away_pen_saved  \\\n",
       "0               69           358             38           69               0   \n",
       "1               76           333             28           76               1   \n",
       "2              110           312             34          110               0   \n",
       "3               78           461             37           78               0   \n",
       "4               83           310             46           83               0   \n",
       "\n",
       "   away_pen_missed  away_pen_scored  away_passes_total  away_crosses_total  \\\n",
       "0                2                3               8057                 403   \n",
       "1                0                0               8942                 277   \n",
       "2                0                0               7248                 288   \n",
       "3                2                6              14887                 526   \n",
       "4                2                2               6376                 443   \n",
       "\n",
       "   Result  \n",
       "0       0  \n",
       "1       2  \n",
       "2       2  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Optimal Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After assigning these labels, we extract the input and output values and split them into separate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([list(x) for x in df.loc[:, 'home_win_total':'away_crosses_total'].values])\n",
    "Y = np.array(df['Result'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use SciKit-Learn's Pipeline and cross-validation-score imports in order to test a series of models with different hidden layer setups. Specifically, we can test the number of hidden layers and the number of nodes in each hidden layer.\n",
    "\n",
    "In order for the tests to be reproducable, I went with a consistent random state seed of 1 for all of my MLPClassifier models.\n",
    "\n",
    "Using the formula in Section 4.2 of a [Neural Networks paper](https://tinyurl.com/ybhoz5ea), I was able to estimate the number of optimal hidden layers and perform a smaller analysis. I also used the guidance on [this StackExchange post](https://tinyurl.com/ydhcc39y) to limit the number of hidden layers to either a single layer or two layers. Three or more hidden layers require an extremely large dataset to draw from, as well as computing power that isn't available to me.\n",
    "\n",
    "*Note: These tests take a long time to run. The analysis I ran is summarized after this section, and the code is left here for re-use, if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(X, Y, n1, n2):\n",
    "    if n2 > 0:\n",
    "        hidden_layers = (n1, n2)\n",
    "    else:\n",
    "        hidden_layers = (n1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    model = MLPClassifier(max_iter=500,\n",
    "                          hidden_layer_sizes=hidden_layers,\n",
    "                          random_state=1)\n",
    "    pipeline = Pipeline([('transform', scaler), ('fit', model)])\n",
    "    return cross_val_score(pipeline, X, Y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hidden_layers(X, Y):\n",
    "    cv_errors = []\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        for n1 in range(1, 15, 1):\n",
    "            nums = ((n1, 0))\n",
    "            cv_errors.append((nums, get_cv_score(X, Y, n1, 0)))\n",
    "\n",
    "        for n1 in range(8, 15, 1):\n",
    "            for n2 in range(8, 15, 1):\n",
    "                nums = ((n1, n2))\n",
    "                cv_errors.append((nums, get_cv_score(X, Y, n1, n2)))\n",
    "    \n",
    "    # return the five best CV errors\n",
    "    cv_errors.sort(key=lambda x: x[1], reverse=True)\n",
    "    return cv_errors[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_hidden_layers(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((9, 8), 0.5884684516279699),\n",
       " ((9, 9), 0.5872224727273606),\n",
       " ((9, 11), 0.586651044155932),\n",
       " ((2, 0), 0.5862703579294973),\n",
       " ((5, 0), 0.5858923984923434)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the five best hidden layer setups are as follows:\n",
    "* (9,8) = **0.5884684516279699**\n",
    "* (9,9) = **0.5872224727273606**\n",
    "* (9,11) = **0.586651044155932**\n",
    "* (2,0) = **0.5862703579294973**\n",
    "* (5,0) = **0.5858923984923434**\n",
    "\n",
    "Most of the other combinations landed between 0.53 and 0.56, with a gradual increase until the above values, followed by a small decrease in cross-validation score, and finally a plateau (around 0.567)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Our Predictions\n",
    "\n",
    "Awesome, now we have the \"optimal\" hidden layer values for the given dataset. Now, we can split the data into test and training subsets and explicitly test how well the model performs, instead of using the above CV score. We can then fit the training dataset to the optimal model and predict the match results of the test dataset. Then, using some more tools from SciKit-Learn, we can view the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) of the predictions, as well as the precision, recall, and [F1-score](https://en.wikipedia.org/wiki/F1_score) of the predictions.\n",
    "\n",
    "I used a random 80% of the training data and used the remaining 20% as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "train_range = range(0, len(X), 1)\n",
    "train_idxs = random.sample(train_range, int(math.floor(len(train_range) * 0.8)))\n",
    "test_idxs = [x for x in train_range if x not in train_idxs]\n",
    "\n",
    "X_train = X[train_idxs]\n",
    "Y_train = Y[train_idxs]\n",
    "\n",
    "X_test = X[test_idxs]\n",
    "Y_test = Y[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    model = MLPClassifier(max_iter=500, hidden_layer_sizes=(9,8), random_state=1)\n",
    "\n",
    "    X_train_std = scaler.transform(X_train)\n",
    "    model.fit(X_train_std, Y_train)\n",
    "\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    predictions = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[731  87 135]\n",
      " [219 171 144]\n",
      " [170  95 350]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(Y_test, predictions, labels=['0', '1', '2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.77      0.71       953\n",
      "          1       0.48      0.32      0.39       534\n",
      "          2       0.56      0.57      0.56       615\n",
      "\n",
      "avg / total       0.58      0.60      0.58      2102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret these:\n",
    "* Correctly predicted (top-left to bottom-right diagonal):\n",
    "  * 731 Home wins\n",
    "  * 171 Draws\n",
    "  * 350 Away wins.\n",
    "  * 1252 correct out of 2102 = **59.6% correct**\n",
    "* Incorrectly predicted:\n",
    "  * Predicted Home wins that were wrong:\n",
    "    * 219 Draws.\n",
    "    * 170 Away wins.\n",
    "  * Predicted Draws that were wrong:\n",
    "    * 87 Home wins.\n",
    "    * 95 Away wins.\n",
    "  * Predicted Away wins that were wrong:\n",
    "    * 135 Home wins.\n",
    "    * 144 Draws.\n",
    "\n",
    "We can see that the Neural Network heavily leans towards Home wins, which backs up the theory that [Home Field Advantage in soccer is huge](http://freakonomics.com/2011/12/18/football-freakonomics-how-advantageous-is-home-field-advantage-and-why/). We can see the results of this in the recall score: Home wins have a 77% chance of being correctly recalled, while draws only have a *32%* chance of being recalled. This huge predictive imbalance between home wins and draws is split almost directly in the middle by correctly predicted away wins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Match Scores\n",
    "Using the same data and MLPClassifier class as above, we can try to predict the amount of goals that each team (home and away) will score. In order to classify these correctly, we have to create labels for expected outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoalsLabel(goals):\n",
    "    return str(goals) if goals < 5 else '5+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen in the above class, any amount of goals greater than or equal to 5 is treated as the same label. There is an extremely low chance that the model will ever predict that both teams will score more than 5 goals, and, if this ever happens, the teams probably deserve to draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_scores = df['home_team_score']\n",
    "df['Home_Result'] = home_scores.apply(getGoalsLabel)\n",
    "\n",
    "away_scores = df['home_team_score']\n",
    "df['Away_Result'] = away_scores.apply(getGoalsLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform the same CV score analysis as we did with the Match Outcome for the number of home and away goals that will be scored in a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([list(x) for x in df.loc[:, 'home_win_total':'away_crosses_total'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Home Result as the outcome variable\n",
    "Y = np.array(df['Home_Result'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 0), 0.35400013767485816), ((2, 0), 0.35579934234273247), ((3, 0), 0.3672453997308855), ((4, 0), 0.36448537297120776), ((5, 0), 0.36848013001283053), ((6, 0), 0.37390402301343884), ((7, 0), 0.36248844462741153), ((8, 0), 0.3541169694205152), ((9, 0), 0.3652702391630903), ((10, 0), 0.3613551912101625), ((11, 0), 0.36764573310464976), ((12, 0), 0.3647847763842161), ((13, 0), 0.35526600494135624), ((14, 0), 0.367366626272157), ((8, 8), 0.3660436559362655), ((8, 9), 0.3622107072483708), ((8, 10), 0.36639921044102), ((8, 11), 0.36820748446808843), ((8, 12), 0.3606860666665036), ((8, 13), 0.36078448932526075), ((8, 14), 0.369630803884229), ((9, 8), 0.3632733890029861), ((9, 9), 0.3648727764978046), ((9, 10), 0.354786195666646), ((9, 11), 0.36278941992152747), ((9, 12), 0.35784559960061874), ((9, 13), 0.3588748126681717), ((9, 14), 0.3603126581719702), ((10, 8), 0.3642264217299148), ((10, 9), 0.36695976633493943), ((10, 10), 0.35736114981064354), ((10, 11), 0.36886579774443484), ((10, 12), 0.36470350816932556), ((10, 13), 0.3620256023632129), ((10, 14), 0.3637383386248205), ((11, 8), 0.3623080349400396), ((11, 9), 0.3603010415088077), ((11, 10), 0.36611040690924856), ((11, 11), 0.3606047138907885), ((11, 12), 0.36983804100132295), ((11, 13), 0.3589848527779), ((11, 14), 0.36014124076490045), ((12, 8), 0.36041097289866386), ((12, 9), 0.35566291579753206), ((12, 10), 0.36736373999529204), ((12, 11), 0.36516355396121986), ((12, 12), 0.3590886872633671), ((12, 13), 0.3638440134263943), ((12, 14), 0.3652656865682794), ((13, 8), 0.36069515602055036), ((13, 9), 0.35796060171581634), ((13, 10), 0.3626962339268729), ((13, 11), 0.36602661420828075), ((13, 12), 0.35745677391894237), ((13, 13), 0.3547057284840155), ((13, 14), 0.3594663891445322), ((14, 8), 0.3585857598802892), ((14, 9), 0.3521356464246788), ((14, 10), 0.36184734394074947), ((14, 11), 0.3615557331855538), ((14, 12), 0.35508079752884425), ((14, 13), 0.3491829761486068), ((14, 14), 0.35899644732951164)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((6, 0), 0.37390402301343884),\n",
       " ((11, 12), 0.36983804100132295),\n",
       " ((8, 14), 0.369630803884229),\n",
       " ((10, 11), 0.36886579774443484),\n",
       " ((5, 0), 0.36848013001283053)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hidden_layers(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the away score\n",
    "Y = np.array(df['Away_Result'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 0), 0.35400013767485816), ((2, 0), 0.35579934234273247), ((3, 0), 0.3672453997308855), ((4, 0), 0.36448537297120776), ((5, 0), 0.36848013001283053), ((6, 0), 0.37390402301343884), ((7, 0), 0.36248844462741153), ((8, 0), 0.3541169694205152), ((9, 0), 0.3652702391630903), ((10, 0), 0.3613551912101625), ((11, 0), 0.36764573310464976), ((12, 0), 0.3647847763842161), ((13, 0), 0.35526600494135624), ((14, 0), 0.367366626272157), ((8, 8), 0.3660436559362655), ((8, 9), 0.3622107072483708), ((8, 10), 0.36639921044102), ((8, 11), 0.36820748446808843), ((8, 12), 0.3606860666665036), ((8, 13), 0.36078448932526075), ((8, 14), 0.369630803884229), ((9, 8), 0.3632733890029861), ((9, 9), 0.3648727764978046), ((9, 10), 0.354786195666646), ((9, 11), 0.36278941992152747), ((9, 12), 0.35784559960061874), ((9, 13), 0.3588748126681717), ((9, 14), 0.3603126581719702), ((10, 8), 0.3642264217299148), ((10, 9), 0.36695976633493943), ((10, 10), 0.35736114981064354), ((10, 11), 0.36886579774443484), ((10, 12), 0.36470350816932556), ((10, 13), 0.3620256023632129), ((10, 14), 0.3637383386248205), ((11, 8), 0.3623080349400396), ((11, 9), 0.3603010415088077), ((11, 10), 0.36611040690924856), ((11, 11), 0.3606047138907885), ((11, 12), 0.36983804100132295), ((11, 13), 0.3589848527779), ((11, 14), 0.36014124076490045), ((12, 8), 0.36041097289866386), ((12, 9), 0.35566291579753206), ((12, 10), 0.36736373999529204), ((12, 11), 0.36516355396121986), ((12, 12), 0.3590886872633671), ((12, 13), 0.3638440134263943), ((12, 14), 0.3652656865682794), ((13, 8), 0.36069515602055036), ((13, 9), 0.35796060171581634), ((13, 10), 0.3626962339268729), ((13, 11), 0.36602661420828075), ((13, 12), 0.35745677391894237), ((13, 13), 0.3547057284840155), ((13, 14), 0.3594663891445322), ((14, 8), 0.3585857598802892), ((14, 9), 0.3521356464246788), ((14, 10), 0.36184734394074947), ((14, 11), 0.3615557331855538), ((14, 12), 0.35508079752884425), ((14, 13), 0.3491829761486068), ((14, 14), 0.35899644732951164)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((6, 0), 0.37390402301343884),\n",
       " ((11, 12), 0.36983804100132295),\n",
       " ((8, 14), 0.369630803884229),\n",
       " ((10, 11), 0.36886579774443484),\n",
       " ((5, 0), 0.36848013001283053)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hidden_layers(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the ideal hidden layer setup is (6,0) for both home and away score, leading to a CV score around 0.374 for both home and away.\n",
    "\n",
    "We can then use the previously determined test and train indices and split the data into 20% testing, 80% training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_home = np.array(df['Home_Result'].values)\n",
    "Y_away = np.array(df['Away_Result'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[train_idxs]\n",
    "Y_train_home = Y_home[train_idxs]\n",
    "Y_train_away = Y_away[train_idxs]\n",
    "\n",
    "X_test = X[test_idxs]\n",
    "Y_test_home = Y_home[test_idxs]\n",
    "Y_test_away = Y_away[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")scaler = StandardScaler()\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    home_team_model = MLPClassifier(max_iter=500, hidden_layer_sizes=(7, 8))\n",
    "    away_team_model = MLPClassifier(max_iter=500, hidden_layer_sizes=(7, 8))\n",
    "\n",
    "    X_train_std = scaler.transform(X_train)\n",
    "\n",
    "    home_team_model.fit(X_train_std, Y_train_home)\n",
    "    away_team_model.fit(X_train_std, Y_train_away)\n",
    "    \n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    home_predictions = home_team_model.predict_probas(X_test_std)\n",
    "    away_predictions = away_team_model.predict_probas(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well this lines up with the actual outcome. We'll take the predictions from both the home and away models and figure out the most likely score, then compare it to the actual score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchPrediction(home_probas, away_probas):\n",
    "    probability = [[], [], [], [], [], []]\n",
    "\n",
    "    for home_idx, home_score in enumerate(home_probas):\n",
    "        for away_idx, away_score in enumerate(away_probas):\n",
    "            probability[home_idx].append(home_score * away_score)\n",
    "\n",
    "    matrix = np.asmatrix(probability)\n",
    "    result = list(np.unravel_index(np.argmax(matrix, axis=None), matrix.shape))\n",
    "    result.append(np.max(matrix, axis=None) * 100)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for home_probas in enumerate(home_predictions):\n",
    "    for away_probas in enumerate(away_predictions):\n",
    "        predictions.append(getMatchPrediction(home_probas, away_probas))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['Score_Result'] = test_df.loc[:, ['Score_Probabilities']].apply(getMost)\n",
    "print(confusion_matrix(Y_test_result, test_df['Most_Probable_Outcome'].apply(str), labels=['0', '1', '2']))\n",
    "print(classification_report(Y_test_result,test_df['Most_Probable_Outcome'].apply(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of use on the website, all of the training data should be easily accessible. Below, I extract the tags for the outcome, home result, and away result and store it in a new table, NeuralNetworkTraining, so that all of the training data can be retrieved with a simple `SELECT * FROM` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# df.to_sql('NeuralNetworkTraining', con=engine, index=False, if_exists='append')\n",
    "# df = pd.read_sql(\"SELECT * FROM neuralnetworktraining\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Documentation\n",
    " - How does it work?\n",
    " - Log file\n",
    " - What's needed to continue the work?\n",
    " - How to run the system\n",
    " \n",
    "External Documentation\n",
    " - How to use the system\n",
    " - Setup, required files, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
